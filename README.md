# ğŸ§  RAG-as-a-Service | Retrieval-Augmented Generation App (LangChain + AWS Bedrock)

A fully-deployed, scalable RAG (Retrieval-Augmented Generation) application that leverages LangChain, Amazon Bedrock, and FastAPI to provide intelligent question-answering over your own data .

## ğŸ”§ Tech Stack

- **LangChain** â€“ LLM orchestration and retrieval logic
- **Amazon Bedrock** â€“ Foundation model access (e.g., Anthropic Claude, Titan, or Llama 3)
- **Amazon S3** â€“ Document storage and ingestion
- **Vector DB** â€“ Document vector storage and similarity search with chromaDB
- **Amazon Lambda** â€“ Serverless backend functions
- **API Gateway** â€“ RESTful API with fastAPI
- **Amazon DynamoDB** â€“ Session/metadata storage (optional)
- **Frontend** â€“ basic CSS and HTML

---

## ğŸš€ Features

- âœ… Upload documents (PDFs, TXT, DOCX, etc.)
- âœ… Chunking, embedding, and vector storage
- âœ… Query interface powered by Bedrock-hosted LLMs
- âœ… Real-time retrieval and context injection (RAG)
- âœ… Streamed responses with token-level feedback (optional)
- âœ… Fully serverless and scalable backend on AWS
- âœ… Secure API with authentication options (API key/Cognito)

---


    F --> G[Generated Response]
    G --> H[Client]
